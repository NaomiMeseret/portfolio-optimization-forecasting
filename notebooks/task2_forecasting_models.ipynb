{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Build Time Series Forecasting Models\n",
    "\n",
    "## Objective\n",
    "Develop, train, and evaluate time series forecasting models to predict Tesla's future stock prices.\n",
    "\n",
    "This notebook covers:\n",
    "1. Data preparation for modeling (chronological train/test split)\n",
    "2. ARIMA/SARIMA model implementation\n",
    "3. LSTM deep learning model\n",
    "4. Model optimization and evaluation\n",
    "5. Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pmdarima as pm\n",
    "\n",
    "# Deep learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data for Modeling\n",
    "\n",
    "We'll focus on TSLA (Tesla) for forecasting. The data will be split chronologically to preserve temporal order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed TSLA data\n",
    "try:\n",
    "    tsla_data = pd.read_csv('../data/processed/TSLA_processed.csv', index_col='Date', parse_dates=True)\n",
    "    print(\"Loaded processed data from file\")\n",
    "except:\n",
    "    # If file doesn't exist, fetch fresh data\n",
    "    import yfinance as yf\n",
    "    print(\"Fetching fresh data from YFinance...\")\n",
    "    stock = yf.Ticker('TSLA')\n",
    "    tsla_data = stock.history(start='2015-01-01', end='2026-01-15')\n",
    "    tsla_data['Daily_Return'] = tsla_data['Close'].pct_change()\n",
    "    tsla_data = tsla_data.dropna()\n",
    "\n",
    "print(f\"Data shape: {tsla_data.shape}\")\n",
    "print(f\"Date range: {tsla_data.index.min()} to {tsla_data.index.max()}\")\n",
    "tsla_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adjusted Close price for forecasting\n",
    "tsla_close = tsla_data['Adj Close'].dropna()\n",
    "\n",
    "# Chronological split: Train on 2015-2024, Test on 2025-2026\n",
    "split_date = '2025-01-01'\n",
    "\n",
    "train_data = tsla_close[tsla_close.index < split_date]\n",
    "test_data = tsla_close[tsla_close.index >= split_date]\n",
    "\n",
    "print(f\"Training set: {len(train_data)} samples ({train_data.index.min()} to {train_data.index.max()})\")\n",
    "print(f\"Test set: {len(test_data)} samples ({test_data.index.min()} to {test_data.index.max()})\")\n",
    "print(f\"Train/Test split: {len(train_data)/(len(train_data)+len(test_data))*100:.1f}% / {len(test_data)/(len(train_data)+len(test_data))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train/test split\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', linewidth=1.5)\n",
    "plt.plot(test_data.index, test_data.values, label='Test Data', linewidth=1.5, color='orange')\n",
    "plt.axvline(x=pd.to_datetime(split_date), color='r', linestyle='--', linewidth=2, label='Split Date')\n",
    "plt.title('TSLA Adjusted Close Price - Train/Test Split', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/train_test_split.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement ARIMA/SARIMA Model\n",
    "\n",
    "### 2.1 Check Stationarity and Determine Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Check stationarity of training data\n",
    "def adf_test(timeseries):\n",
    "    adf_result = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    print(f'ADF Statistic: {adf_result[0]:.6f}')\n",
    "    print(f'p-value: {adf_result[1]:.6f}')\n",
    "    if adf_result[1] <= 0.05:\n",
    "        print('✓ Series is STATIONARY')\n",
    "        return True\n",
    "    else:\n",
    "        print('✗ Series is NON-STATIONARY - Differencing required')\n",
    "        return False\n",
    "\n",
    "print(\"Stationarity Test on Training Data:\")\n",
    "is_stationary = adf_test(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF to help determine ARIMA parameters\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# ACF plot\n",
    "plot_acf(train_data.dropna(), lags=40, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# PACF plot\n",
    "plot_pacf(train_data.dropna(), lags=40, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/acf_pacf_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Auto ARIMA for Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auto_arima to find optimal ARIMA parameters\n",
    "print(\"Finding optimal ARIMA parameters using auto_arima...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "auto_arima_model = pm.auto_arima(\n",
    "    train_data,\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=5, max_q=5,\n",
    "    start_P=0, start_Q=0,\n",
    "    max_P=2, max_Q=2,\n",
    "    m=12,  # Monthly seasonality\n",
    "    seasonal=True,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore',\n",
    "    trace=True\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimal ARIMA parameters: {auto_arima_model.order}\")\n",
    "print(f\"Optimal SARIMA parameters: {auto_arima_model.seasonal_order}\")\n",
    "print(f\"\\nAIC: {auto_arima_model.aic():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fit ARIMA/SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the optimal parameters\n",
    "arima_order = auto_arima_model.order\n",
    "seasonal_order = auto_arima_model.seasonal_order\n",
    "\n",
    "print(f\"Fitting SARIMA{arima_order}{seasonal_order} model...\")\n",
    "\n",
    "# Fit SARIMA model\n",
    "sarima_model = SARIMAX(\n",
    "    train_data,\n",
    "    order=arima_order,\n",
    "    seasonal_order=seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "\n",
    "fitted_sarima = sarima_model.fit(disp=False)\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(fitted_sarima.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts for test period\n",
    "forecast_steps = len(test_data)\n",
    "sarima_forecast = fitted_sarima.forecast(steps=forecast_steps)\n",
    "sarima_forecast_ci = fitted_sarima.get_forecast(steps=forecast_steps).conf_int()\n",
    "\n",
    "# Create forecast dataframe\n",
    "sarima_forecast_df = pd.DataFrame({\n",
    "    'Forecast': sarima_forecast.values,\n",
    "    'Lower_CI': sarima_forecast_ci.iloc[:, 0].values,\n",
    "    'Upper_CI': sarima_forecast_ci.iloc[:, 1].values\n",
    "}, index=test_data.index)\n",
    "\n",
    "print(f\"Generated {len(sarima_forecast)} forecasts\")\n",
    "sarima_forecast_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize ARIMA/SARIMA Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA/SARIMA forecasts\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot training data (last 500 days for clarity)\n",
    "train_plot = train_data.tail(500)\n",
    "plt.plot(train_plot.index, train_plot.values, label='Training Data (last 500 days)', linewidth=1.5, color='blue')\n",
    "\n",
    "# Plot test data\n",
    "plt.plot(test_data.index, test_data.values, label='Actual Test Data', linewidth=2, color='green')\n",
    "\n",
    "# Plot forecasts\n",
    "plt.plot(sarima_forecast_df.index, sarima_forecast_df['Forecast'], \n",
    "         label='SARIMA Forecast', linewidth=2, color='red', linestyle='--')\n",
    "\n",
    "# Plot confidence intervals\n",
    "plt.fill_between(sarima_forecast_df.index, \n",
    "                 sarima_forecast_df['Lower_CI'], \n",
    "                 sarima_forecast_df['Upper_CI'], \n",
    "                 alpha=0.3, color='red', label='95% Confidence Interval')\n",
    "\n",
    "plt.axvline(x=pd.to_datetime(split_date), color='black', linestyle='--', linewidth=1, label='Train/Test Split')\n",
    "plt.title('SARIMA Model Forecast vs Actual', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/sarima_forecast.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement LSTM Model\n",
    "\n",
    "### 3.1 Prepare Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data for LSTM (important for neural networks)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale training data\n",
    "train_scaled = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "\n",
    "# Scale test data using training scaler\n",
    "test_scaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "\n",
    "print(f\"Training data shape (scaled): {train_scaled.shape}\")\n",
    "print(f\"Test data shape (scaled): {test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for LSTM\n",
    "# Use last 60 days to predict next day\n",
    "def create_sequences(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i, 0])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 60\n",
    "\n",
    "# Create training sequences\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "\n",
    "# For test data, we need to create sequences from the end of training data\n",
    "# Combine last part of training data with test data for sequence creation\n",
    "combined_for_test = np.concatenate([train_scaled[-seq_length:], test_scaled])\n",
    "X_test, y_test = create_sequences(combined_for_test, seq_length)\n",
    "\n",
    "# Reshape for LSTM: (samples, time_steps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(f\"Training sequences: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test sequences: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(\"LSTM Model Architecture:\")\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training LSTM model...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=10)\n",
    "axes[0].set_ylabel('Loss', fontsize=10)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_title('Model MAE', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=10)\n",
    "axes[1].set_ylabel('MAE', fontsize=10)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/lstm_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Generate LSTM Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "lstm_predictions_scaled = lstm_model.predict(X_test, verbose=0)\n",
    "\n",
    "# Inverse transform to get actual price predictions\n",
    "lstm_forecast = scaler.inverse_transform(lstm_predictions_scaled).flatten()\n",
    "\n",
    "# Create forecast dataframe aligned with test data\n",
    "lstm_forecast_df = pd.DataFrame({\n",
    "    'Forecast': lstm_forecast\n",
    "}, index=test_data.index[:len(lstm_forecast)])\n",
    "\n",
    "print(f\"Generated {len(lstm_forecast)} LSTM forecasts\")\n",
    "lstm_forecast_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Visualize LSTM Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LSTM forecasts\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot training data (last 500 days)\n",
    "train_plot = train_data.tail(500)\n",
    "plt.plot(train_plot.index, train_plot.values, label='Training Data (last 500 days)', linewidth=1.5, color='blue')\n",
    "\n",
    "# Plot test data\n",
    "test_plot = test_data.iloc[:len(lstm_forecast)]\n",
    "plt.plot(test_plot.index, test_plot.values, label='Actual Test Data', linewidth=2, color='green')\n",
    "\n",
    "# Plot forecasts\n",
    "plt.plot(lstm_forecast_df.index, lstm_forecast_df['Forecast'], \n",
    "         label='LSTM Forecast', linewidth=2, color='red', linestyle='--')\n",
    "\n",
    "plt.axvline(x=pd.to_datetime(split_date), color='black', linestyle='--', linewidth=1, label='Train/Test Split')\n",
    "plt.title('LSTM Model Forecast vs Actual', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/lstm_forecast.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Compare Models\n",
    "\n",
    "### 4.1 Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(actual, predicted, model_name):\n",
    "    \"\"\"\n",
    "    Calculate MAE, RMSE, and MAPE\n",
    "    \"\"\"\n",
    "    # Align actual and predicted arrays\n",
    "    min_len = min(len(actual), len(predicted))\n",
    "    actual_aligned = actual[:min_len]\n",
    "    predicted_aligned = predicted[:min_len]\n",
    "    \n",
    "    mae = mean_absolute_error(actual_aligned, predicted_aligned)\n",
    "    rmse = np.sqrt(mean_squared_error(actual_aligned, predicted_aligned))\n",
    "    mape = np.mean(np.abs((actual_aligned - predicted_aligned) / actual_aligned)) * 100\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE (%)': mape\n",
    "    }\n",
    "\n",
    "# Calculate metrics for SARIMA\n",
    "sarima_metrics = calculate_metrics(\n",
    "    test_data.values, \n",
    "    sarima_forecast_df['Forecast'].values, \n",
    "    'SARIMA'\n",
    ")\n",
    "\n",
    "# Calculate metrics for LSTM\n",
    "lstm_metrics = calculate_metrics(\n",
    "    test_data.iloc[:len(lstm_forecast)].values,\n",
    "    lstm_forecast_df['Forecast'].values,\n",
    "    'LSTM'\n",
    ")\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame([sarima_metrics, lstm_metrics])\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'MAPE (%)']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    axes[idx].bar(comparison_df['Model'], comparison_df[metric], color=['skyblue', 'lightcoral'])\n",
    "    axes[idx].set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(metric, fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(comparison_df[metric]):\n",
    "        axes[idx].text(i, v, f'{v:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/model_comparison_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Side-by-Side Forecast Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both models side by side\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# SARIMA plot\n",
    "train_plot = train_data.tail(500)\n",
    "axes[0].plot(train_plot.index, train_plot.values, label='Training Data (last 500 days)', linewidth=1, color='blue', alpha=0.7)\n",
    "test_plot_sarima = test_data.iloc[:len(sarima_forecast_df)]\n",
    "axes[0].plot(test_plot_sarima.index, test_plot_sarima.values, label='Actual', linewidth=2, color='green')\n",
    "axes[0].plot(sarima_forecast_df.index, sarima_forecast_df['Forecast'], \n",
    "             label='SARIMA Forecast', linewidth=2, color='red', linestyle='--')\n",
    "axes[0].fill_between(sarima_forecast_df.index, \n",
    "                     sarima_forecast_df['Lower_CI'], \n",
    "                     sarima_forecast_df['Upper_CI'], \n",
    "                     alpha=0.2, color='red')\n",
    "axes[0].set_title(f'SARIMA Model (MAE: {sarima_metrics[\"MAE\"]:.2f}, RMSE: {sarima_metrics[\"RMSE\"]:.2f})', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Price (USD)', fontsize=10)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# LSTM plot\n",
    "axes[1].plot(train_plot.index, train_plot.values, label='Training Data (last 500 days)', linewidth=1, color='blue', alpha=0.7)\n",
    "test_plot_lstm = test_data.iloc[:len(lstm_forecast_df)]\n",
    "axes[1].plot(test_plot_lstm.index, test_plot_lstm.values, label='Actual', linewidth=2, color='green')\n",
    "axes[1].plot(lstm_forecast_df.index, lstm_forecast_df['Forecast'], \n",
    "             label='LSTM Forecast', linewidth=2, color='red', linestyle='--')\n",
    "axes[1].set_title(f'LSTM Model (MAE: {lstm_metrics[\"MAE\"]:.2f}, RMSE: {lstm_metrics[\"RMSE\"]:.2f})', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Date', fontsize=10)\n",
    "axes[1].set_ylabel('Price (USD)', fontsize=10)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/both_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Selection Rationale\n",
    "\n",
    "### Discussion of Results\n",
    "\n",
    "**SARIMA Model:**\n",
    "- **Strengths**: Interpretable, provides confidence intervals, good for capturing seasonal patterns\n",
    "- **Weaknesses**: Assumes linear relationships, may struggle with complex non-linear patterns\n",
    "- **Best for**: When interpretability is important, when data shows clear seasonal patterns\n",
    "\n",
    "**LSTM Model:**\n",
    "- **Strengths**: Can capture complex non-linear patterns, learns from sequences, flexible architecture\n",
    "- **Weaknesses**: Less interpretable, requires more data and computational resources, prone to overfitting\n",
    "- **Best for**: When dealing with complex patterns, when sufficient data is available\n",
    "\n",
    "**Which Model Performed Better?**\n",
    "\n",
    "Based on the metrics (MAE, RMSE, MAPE), the model with lower values generally performs better. However, the choice depends on:\n",
    "\n",
    "1. **Business Context**: If interpretability is crucial (e.g., explaining to clients), SARIMA may be preferred\n",
    "2. **Data Characteristics**: If the data has strong seasonal patterns, SARIMA may excel\n",
    "3. **Complexity**: If the relationships are highly non-linear, LSTM may capture them better\n",
    "4. **Resources**: LSTM requires more computational power and time to train\n",
    "\n",
    "**Recommendation**: Use both models as part of an ensemble approach, or select based on the specific use case and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results\n",
    "comparison_df.to_csv('../data/processed/model_comparison_results.csv', index=False)\n",
    "sarima_forecast_df.to_csv('../data/processed/sarima_forecasts.csv')\n",
    "lstm_forecast_df.to_csv('../data/processed/lstm_forecasts.csv')\n",
    "\n",
    "print(\"Results saved to ../data/processed/\")\n",
    "print(\"\\nModel Parameters:\")\n",
    "print(f\"SARIMA Order: {arima_order}\")\n",
    "print(f\"SARIMA Seasonal Order: {seasonal_order}\")\n",
    "print(f\"LSTM Architecture: 3 LSTM layers (50 units each) + Dropout + Dense output\")\n",
    "print(f\"LSTM Sequence Length: {seq_length} days\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
