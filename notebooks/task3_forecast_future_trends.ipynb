{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Forecast Future Market Trends\n",
        "\n",
        "## Objective\n",
        "Use the best-performing forecasting model from Task 2 to predict Tesla's future stock prices, visualize forecasts with confidence intervals, and extract actionable insights about trends, opportunities, and risks.\n",
        "\n",
        "> Prerequisite: Run Task 1 and Task 2 first so that processed data and model comparison results exist in `../data/processed/`."
      ],
      "id": "452d89e2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1. Imports and configuration\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import timedelta\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully for Task 3.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries imported successfully for Task 3.\n"
          ]
        }
      ],
      "id": "036e58c6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2. Load processed TSLA data and model comparison results\n",
        "\n",
        "# Load TSLA processed data created in Task 1\n",
        "tsla_data = pd.read_csv('../data/processed/TSLA_processed.csv', index_col='Date', parse_dates=True)\n",
        "\n",
        "# Use Adjusted Close price for forecasting (fallback to Close if Adj Close not available)\n",
        "if 'Adj Close' in tsla_data.columns:\n",
        "    tsla_close = tsla_data['Adj Close'].dropna()\n",
        "    print(\"Using 'Adj Close' column\")\n",
        "else:\n",
        "    tsla_close = tsla_data['Close'].dropna()\n",
        "    print(\"Using 'Close' column (Adj Close not found)\")\n",
        "\n",
        "# Chronological split (same as Task 2) — use UTC-safe comparison\n",
        "split_date = '2025-01-01'\n",
        "# Convert index to UTC-aware DatetimeIndex to handle tz-aware/naive mixes\n",
        "idx_utc = pd.to_datetime(tsla_close.index, utc=True)\n",
        "# Prepare split timestamp as UTC-aware\n",
        "split_ts = pd.Timestamp(split_date)\n",
        "if split_ts.tz is None:\n",
        "    split_ts_utc = split_ts.tz_localize('UTC')\n",
        "else:\n",
        "    split_ts_utc = split_ts.tz_convert('UTC')\n",
        "# Boolean mask and slicing (preserve original series/index types)\n",
        "mask = idx_utc < split_ts_utc\n",
        "train_data = tsla_close.iloc[mask]\n",
        "test_data = tsla_close.iloc[~mask]\n",
        "\n",
        "print(f\"Training set: {train_data.index.min()} -> {train_data.index.max()} ({len(train_data)} points)\")\n",
        "print(f\"Test set: {test_data.index.min()} -> {test_data.index.max()} ({len(test_data)} points)\")\n",
        "\n",
        "# Try loading model comparison results from Task 2; if missing, infer from cached artifacts\n",
        "comparison_csv = '../data/processed/model_comparison_results.csv'\n",
        "best_model_name = None\n",
        "if os.path.exists(comparison_csv):\n",
        "    comparison_df = pd.read_csv(comparison_csv)\n",
        "    print(\"\\nModel performance from Task 2:\")\n",
        "    print(comparison_df.to_string(index=False))\n",
        "    # Select best model based on RMSE\n",
        "    best_row = comparison_df.loc[comparison_df['RMSE'].idxmin()]\n",
        "    best_model_name = best_row['Model']\n",
        "else:\n",
        "    print(\"Model comparison CSV not found; inferring best model from cached artifacts...\")\n",
        "    sarima_path = '../data/processed/sarima_model.pkl'\n",
        "    lstm_path = '../data/processed/lstm_model.h5'\n",
        "    if os.path.exists(sarima_path) and os.path.exists(lstm_path):\n",
        "        print(\"Both SARIMA and LSTM artifacts found. Defaulting to 'SARIMA'.\")\n",
        "        best_model_name = 'SARIMA'\n",
        "    elif os.path.exists(sarima_path):\n",
        "        print(\"Found SARIMA model artifact. Selecting 'SARIMA'.\")\n",
        "        best_model_name = 'SARIMA'\n",
        "    elif os.path.exists(lstm_path):\n",
        "        print(\"Found LSTM model artifact. Selecting 'LSTM'.\")\n",
        "        best_model_name = 'LSTM'\n",
        "    else:\n",
        "        print(\"No model artifacts found. Defaulting to 'SARIMA'.\")\n",
        "        best_model_name = 'SARIMA'\n",
        "\n",
        "print(f\"\\nBest-performing model based on available artifacts: {best_model_name}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 'Close' column (Adj Close not found)\n",
            "Training set: 2015-01-02 00:00:00-05:00 -> 2024-12-31 00:00:00-05:00 (2516 points)\n",
            "Test set: 2025-01-02 00:00:00-05:00 -> 2026-01-14 00:00:00-05:00 (259 points)\n",
            "Model comparison CSV not found; inferring best model from cached artifacts...\n",
            "Found SARIMA model artifact. Selecting 'SARIMA'.\n",
            "\n",
            "Best-performing model based on available artifacts: SARIMA\n"
          ]
        }
      ],
      "id": "80e8a79a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate 6–12 Month Ahead Forecasts\n",
        "\n",
        "We:\n",
        "- Refit the best model on the full TSLA series (train + test).\n",
        "- Generate multi-step forecasts (≈12 months of trading days).\n",
        "- For SARIMA, we also obtain confidence intervals from the model.\n",
        "- For LSTM, we generate forecasts iteratively using the last 60 days of data as the starting window."
      ],
      "id": "9d2556c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3.1 SARIMA-based future forecasts (if SARIMA is best)\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import pmdarima as pm\n",
        "\n",
        "forecast_steps = 252  # ~12 months of trading days\n",
        "\n",
        "sarima_future_df = None\n",
        "\n",
        "if best_model_name == 'SARIMA':\n",
        "    print(\"Best model is SARIMA – refitting on full TSLA series...\")\n",
        "\n",
        "    auto_arima_model = pm.auto_arima(\n",
        "        tsla_close,\n",
        "        start_p=0, start_q=0,\n",
        "        max_p=5, max_q=5,\n",
        "        start_P=0, start_Q=0,\n",
        "        max_P=2, max_Q=2,\n",
        "        m=12,                 # assume monthly seasonality\n",
        "        seasonal=True,\n",
        "        stepwise=True,\n",
        "        suppress_warnings=True,\n",
        "        error_action='ignore',\n",
        "        trace=False\n",
        "    )\n",
        "\n",
        "    arima_order = auto_arima_model.order\n",
        "    seasonal_order = auto_arima_model.seasonal_order\n",
        "    print(f\"Selected SARIMA order: {arima_order}, seasonal order: {seasonal_order}\")\n",
        "\n",
        "    sarima_model = SARIMAX(\n",
        "        tsla_close,\n",
        "        order=arima_order,\n",
        "        seasonal_order=seasonal_order,\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False\n",
        "    )\n",
        "\n",
        "    fitted_sarima = sarima_model.fit(disp=False)\n",
        "\n",
        "    sarima_future = fitted_sarima.get_forecast(steps=forecast_steps)\n",
        "    future_mean = sarima_future.predicted_mean\n",
        "    future_ci = sarima_future.conf_int()\n",
        "\n",
        "    last_date = tsla_close.index[-1]\n",
        "    future_index = pd.bdate_range(start=last_date + timedelta(days=1), periods=forecast_steps)\n",
        "\n",
        "    sarima_future_df = pd.DataFrame({\n",
        "        'Forecast': future_mean.values,\n",
        "        'Lower_CI': future_ci.iloc[:, 0].values,\n",
        "        'Upper_CI': future_ci.iloc[:, 1].values\n",
        "    }, index=future_index)\n",
        "\n",
        "    print(\"Generated SARIMA future forecasts:\")\n",
        "    display(sarima_future_df.head())\n",
        "else:\n",
        "    print(\"Best model is not SARIMA – this cell will be skipped.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "36b47a65"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3.2 LSTM-based future forecasts (if LSTM is best)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "lstm_future_df = None\n",
        "\n",
        "if best_model_name == 'LSTM':\n",
        "    print(\"Best model is LSTM – preparing data and refitting...\")\n",
        "\n",
        "    # Scale the full Adjusted Close series\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    tsla_scaled = scaler.fit_transform(tsla_close.values.reshape(-1, 1))\n",
        "\n",
        "    seq_length = 60\n",
        "\n",
        "    # Use only the training portion to build sequences for training\n",
        "    train_scaled = scaler.transform(train_data.values.reshape(-1, 1))\n",
        "\n",
        "    def create_sequences(data, seq_len=60):\n",
        "        X, y = [], []\n",
        "        for i in range(seq_len, len(data)):\n",
        "            X.append(data[i-seq_len:i, 0])\n",
        "            y.append(data[i, 0])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    X_train, y_train = create_sequences(train_scaled, seq_length)\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "    # Build LSTM architecture (same style as Task 2)\n",
        "    lstm_model = Sequential([\n",
        "        LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
        "        Dropout(0.2),\n",
        "        LSTM(50, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(50),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    lstm_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    history = lstm_model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Iterative multi-step forecast\n",
        "    last_seq = tsla_scaled[-seq_length:].reshape(1, seq_length, 1)\n",
        "    future_scaled = []\n",
        "\n",
        "    for _ in range(forecast_steps):\n",
        "        next_pred = lstm_model.predict(last_seq, verbose=0)[0, 0]\n",
        "        future_scaled.append(next_pred)\n",
        "        # slide window\n",
        "        last_seq = np.append(last_seq[:, 1:, :], [[[next_pred]]], axis=1)\n",
        "\n",
        "    future_scaled = np.array(future_scaled).reshape(-1, 1)\n",
        "    future_prices = scaler.inverse_transform(future_scaled).flatten()\n",
        "\n",
        "    last_date = tsla_close.index[-1]\n",
        "    future_index = pd.bdate_range(start=last_date + timedelta(days=1), periods=forecast_steps)\n",
        "\n",
        "    lstm_future_df = pd.DataFrame({'Forecast': future_prices}, index=future_index)\n",
        "\n",
        "    print(\"Generated LSTM future forecasts:\")\n",
        "    display(lstm_future_df.head())\n",
        "else:\n",
        "    print(\"Best model is not LSTM – this cell will be skipped.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "",
          "evalue": "",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "id": "bf588632"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Historical Data, Test Set, and Future Forecasts\n",
        "\n",
        "We now:\n",
        "- Plot the full historical Adjusted Close series.\n",
        "- Highlight the test period used in Task 2.\n",
        "- Overlay the future forecasts from the selected best model.\n",
        "- Show confidence intervals when available (SARIMA)."
      ],
      "id": "3ead73bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 4.1 Plot historical data, test period, and future forecasts\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Historical TSLA Adjusted Close\n",
        "plt.plot(tsla_close.index, tsla_close.values, label='Historical TSLA (Adj Close)', color='blue', linewidth=1.5)\n",
        "\n",
        "# Test period highlight\n",
        "plt.plot(test_data.index, test_data.values, label='Test Period (Task 2)', color='green', linewidth=2)\n",
        "\n",
        "# Future forecasts from selected best model\n",
        "if best_model_name == 'SARIMA' and sarima_future_df is not None:\n",
        "    plt.plot(sarima_future_df.index, sarima_future_df['Forecast'],\n",
        "             label='SARIMA Future Forecast', color='red', linestyle='--', linewidth=2)\n",
        "    plt.fill_between(\n",
        "        sarima_future_df.index,\n",
        "        sarima_future_df['Lower_CI'],\n",
        "        sarima_future_df['Upper_CI'],\n",
        "        color='red', alpha=0.2, label='95% Confidence Interval'\n",
        "    )\n",
        "elif best_model_name == 'LSTM' and lstm_future_df is not None:\n",
        "    plt.plot(lstm_future_df.index, lstm_future_df['Forecast'],\n",
        "             label='LSTM Future Forecast', color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "plt.axvline(test_data.index[0], color='black', linestyle='--', linewidth=1, label='Train/Test Split (2025-01-01)')\n",
        "\n",
        "plt.title('TSLA – Historical Prices, Test Period, and 12-Month Forecast', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../data/processed/task3_tsla_future_forecast.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 4.1 Plot historical data, test period, and future forecasts\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m16\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Historical TSLA Adjusted Close\u001b[39;00m\n\u001b[32m      6\u001b[39m plt.plot(tsla_close.index, tsla_close.values, label=\u001b[33m'\u001b[39m\u001b[33mHistorical TSLA (Adj Close)\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m1.5\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
          ]
        }
      ],
      "id": "9fb757fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Task Complete\n",
        "\n",
        "Forecast visualization and data have been generated. \n",
        "\n",
        "**Note:** Trend analysis, opportunities, risks, and conclusions are documented in `final_report.ipynb` (Section 4.3)."
      ],
      "id": "e2ae647b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}